# ğŸ“° News RAG Chatbot -- Backend API

A production-ready backend service for a **Retrieval-Augmented
Generation (RAG) News Chatbot**, built using Node.js, Qdrant, Redis,
Jina Embeddings, and Google Gemini. It ingests real-time news, stores
semantic vectors, retrieves context, and generates grounded AI
responses.

## â­ Overview

This backend handles:

-   Fetching and chunking news articles from RSS feeds\
-   Generating embedding vectors using **Jina Embeddings v2**\
-   Storing and searching vectors in **Qdrant**\
-   Maintaining chat sessions using **Redis**\
-   Generating context-aware responses using **Google Gemini**\
-   Exposing REST APIs for chat interactions and session management

## ğŸ› ï¸ Tech Stack

  Component          Technology
  ------------------ ------------------------
  Runtime            Node.js (Express.js)
  LLM                Google Gemini
  Embeddings         Jina Embeddings v2
  Vector Database    Qdrant (Docker)
  Cache / Sessions   Redis (Docker)
  Data Source        RSS Feeds (TechCrunch)

## ğŸš€ Features

### ğŸ”¹ RAG Pipeline

-   Fetches news from RSS\
-   Chunks content\
-   Generates embeddings\
-   Stores semantic vectors in Qdrant

### ğŸ”¹ Context-Aware Chat

-   Retrieves top-k relevant articles\
-   Sends grounded context to Gemini\
-   Produces fact-based answers

### ğŸ”¹ Session Management

-   Chat history stored per session in Redis\
-   TTL: **24 hours**\
-   Automatic cleanup of inactive sessions

## ğŸ“‚ Project Structure

    rag-backend/
    â”‚â”€â”€ ingest.js
    â”‚â”€â”€ server.js
    â”‚â”€â”€ utils/
    â”‚     â””â”€â”€ jina.js
    â”‚â”€â”€ services/
    â”‚     â”œâ”€â”€ qdrant.js
    â”‚     â””â”€â”€ redis.js
    â”‚â”€â”€ routes/
    â”‚     â””â”€â”€ chat.js
    â”‚â”€â”€ .env
    â”‚â”€â”€ package.json
    â””â”€â”€ README.md

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Prerequisites

-   Node.js v18+\
-   Docker installed

### 2ï¸âƒ£ Start Required Services

#### Start Qdrant

``` bash
docker run -d -p 6333:6333   -v $(pwd)/qdrant_storage:/qdrant/storage   qdrant/qdrant
```

#### Start Redis

``` bash
docker run -d -p 6379:6379 redis
```

### 3ï¸âƒ£ Install Dependencies

``` bash
npm install
```

### 4ï¸âƒ£ Environment Variables

Create a `.env` file:

    JINA_API_KEY=your_jina_api_key
    GEMINI_API_KEY=your_gemini_api_key

### 5ï¸âƒ£ Ingest News Articles

``` bash
node ingest.js
```

Expected output:

    âœ… Ingestion complete! Articles indexed.

### 6ï¸âƒ£ Start the Server

``` bash
node server.js
```

Server runs at:\
**http://localhost:3000**

## ğŸ“¡ API Endpoints

### **POST /api/chat**

Request:

``` json
{
  "sessionId": "uuid",
  "message": "Whatâ€™s the latest in AI?"
}
```

Response:

``` json
{
  "reply": "Here is the latest update..."
}
```

### **GET /api/session/:sessionId**

Retrieve chat history.

### **DELETE /api/session/:sessionId**

Clear chat history.

## ğŸ§  Design Decisions

### âœ” Qdrant for Vector Search

Fast cosine similarity search with easy Docker deployment.

### âœ” Redis for Session Storage

Low latency, per-session history, 24-hour TTL for auto-cleanup.

### âœ” Jina Embeddings v2

Accurate embeddings with simple API integration.

## ğŸ“ Summary

This backend provides a clean, modular, and scalable RAG system using
modern AI tools. It supports semantic search, grounded chat responses,
and efficient session handling.
